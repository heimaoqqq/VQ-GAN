{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/explainingai-code/StableDiffusion-PyTorch.git\n",
    "%cd StableDiffusion-PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p models/weights/v0.1\n",
    "!wget -O models/weights/v0.1/vgg.pth https://github.com/richzhang/PerceptualSimilarity/raw/master/lpips/weights/v0.1/vgg.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 创建数据集类文件\n",
    "!mkdir -p dataset\n",
    "\n",
    "with open('dataset/doppler_dataset.py', 'w') as f:\n",
    "    f.write(\"\"\"import glob\n",
    "import os\n",
    "import random\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from utils.diffusion_utils import load_latents\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class DopplerDataset(Dataset):\n",
    "    def __init__(self, split, im_path, im_size, im_channels,\n",
    "                 use_latents=False, latent_path=None, condition_config=None,\n",
    "                 train_ratio=0.8, seed=42):\n",
    "        self.split = split\n",
    "        self.im_size = im_size\n",
    "        self.im_channels = im_channels\n",
    "        self.latent_maps = None\n",
    "        self.use_latents = False\n",
    "        self.condition_types = [] if condition_config is None else condition_config['condition_types']\n",
    "        self.image_to_class = {}\n",
    "        \n",
    "        # 加载所有图像路径\n",
    "        all_images = self.load_nested_images(im_path)\n",
    "        \n",
    "        # 划分数据集(8:2)\n",
    "        self.images = self.split_dataset(all_images, train_ratio, seed)\n",
    "        \n",
    "        # 加载潜在表示\n",
    "        if use_latents and latent_path is not None:\n",
    "            latent_maps = load_latents(latent_path)\n",
    "            if len(latent_maps) > 0:\n",
    "                self.use_latents = True\n",
    "                self.latent_maps = latent_maps\n",
    "                print(f'找到{len(self.latent_maps)}个潜在表示')\n",
    "            else:\n",
    "                print('未找到潜在表示')\n",
    "    \n",
    "    def load_nested_images(self, dataset_root):\n",
    "        assert os.path.exists(dataset_root), f\"数据集目录{dataset_root}不存在\"\n",
    "        all_images = []\n",
    "        \n",
    "        # 获取所有ID子目录\n",
    "        id_folders = [f for f in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, f)) and f.startswith('ID_')]\n",
    "        id_folders.sort()\n",
    "        \n",
    "        # 构建ID到类别索引的映射\n",
    "        id_to_class = {folder: idx for idx, folder in enumerate(id_folders)}\n",
    "        \n",
    "        for id_folder in tqdm(id_folders):\n",
    "            folder_path = os.path.join(dataset_root, id_folder)\n",
    "            \n",
    "            # 支持多种图像格式\n",
    "            for ext in ['*.png', '*.jpg', '*.jpeg']:\n",
    "                image_paths = glob.glob(os.path.join(folder_path, ext))\n",
    "                \n",
    "                for img_path in image_paths:\n",
    "                    self.image_to_class[img_path] = id_to_class[id_folder]\n",
    "                    all_images.append(img_path)\n",
    "        \n",
    "        print(f'共找到{len(all_images)}张图像，来自{len(id_folders)}个用户ID')\n",
    "        \n",
    "        # 保存类别映射信息 - 修改为使用Kaggle可写目录\n",
    "        os.makedirs(os.path.join('/kaggle/working', 'metadata'), exist_ok=True)\n",
    "        import json\n",
    "        with open(os.path.join('/kaggle/working', 'metadata', 'class_mapping.json'), 'w') as f:\n",
    "            json.dump({\n",
    "                'id_to_class': id_to_class,\n",
    "                'num_classes': len(id_folders)\n",
    "            }, f)\n",
    "        \n",
    "        return all_images\n",
    "    \n",
    "    def split_dataset(self, all_images, train_ratio, seed):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(all_images)\n",
    "        \n",
    "        train_size = int(len(all_images) * train_ratio)\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            images = all_images[:train_size]\n",
    "        else:  # val\n",
    "            images = all_images[train_size:]\n",
    "            \n",
    "        print(f'{self.split}集包含{len(images)}张图像')\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            split_info = {\n",
    "                'train': all_images[:train_size],\n",
    "                'val': all_images[train_size:]\n",
    "            }\n",
    "            \n",
    "            # 修改为使用Kaggle可写目录\n",
    "            os.makedirs(os.path.join('/kaggle/working', 'metadata'), exist_ok=True)\n",
    "            import pickle\n",
    "            with open(os.path.join('/kaggle/working', 'metadata', 'split_info.pkl'), 'wb') as f:\n",
    "                pickle.dump(split_info, f)\n",
    "            \n",
    "            print(f\"数据集划分完成: 训练集={len(split_info['train'])}张, 验证集={len(split_info['val'])}张\")\n",
    "            \n",
    "        return images\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.use_latents:\n",
    "            latent = self.latent_maps[self.images[index]]\n",
    "            return latent\n",
    "        else:\n",
    "            im = Image.open(self.images[index])\n",
    "            im = im.resize((self.im_size, self.im_size))\n",
    "            im_tensor = torchvision.transforms.ToTensor()(im)\n",
    "            \n",
    "            # 转换为-1到1范围\n",
    "            im_tensor = (2 * im_tensor) - 1\n",
    "            return im_tensor\n",
    "\"\"\")\n",
    "\n",
    "print(\"数据集类文件已创建\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('config/doppler.yaml', 'w') as f:\n",
    "    f.write(\"\"\"dataset_params:\n",
    "  im_path: '/kaggle/input/dataset'\n",
    "  im_channels: 3\n",
    "  im_size: 256  # 保持原分辨率\n",
    "  name: 'doppler'\n",
    "\n",
    "dataset_params:\n",
    "  im_path: '/kaggle/input/dataset'\n",
    "  im_channels: 3\n",
    "  im_size: 256\n",
    "  name: 'doppler'\n",
    "\n",
    "diffusion_params:\n",
    "  num_timesteps: 1000\n",
    "  beta_start: 0.0015\n",
    "  beta_end: 0.0195\n",
    "\n",
    "ldm_params:\n",
    "  down_channels: [128, 256, 256, 256]  # 调整为能被8整除\n",
    "  mid_channels: [256, 256]  # 调整为能被8整除\n",
    "  down_sample: [True, True, False]\n",
    "  attn_down: [False, False, True]\n",
    "  time_emb_dim: 256  # 调整为与通道数匹配\n",
    "  norm_channels: 64  # 调整为能被8整除\n",
    "  num_heads: 8  # 从4增加到8\n",
    "  conv_out_channels: 128  # 调整为能被8整除\n",
    "  num_down_layers: 1\n",
    "  num_mid_layers: 1\n",
    "  num_up_layers: 1\n",
    "\n",
    "autoencoder_params:\n",
    "  z_channels: 3\n",
    "  codebook_size: 512  # 已提高到512\n",
    "  down_channels: [64, 128, 128]  # 调整为能被8整除\n",
    "  mid_channels: [128, 128]  # 调整为能被8整除\n",
    "  down_sample: [True, True]\n",
    "  attn_down: [False, False]\n",
    "  norm_channels: 64  # 调整为能被8整除\n",
    "  num_heads: 8  # 从4增加到8\n",
    "  num_down_layers: 1\n",
    "  num_mid_layers: 1\n",
    "  num_up_layers: 1\n",
    "\n",
    "train_params:\n",
    "  # 其他参数保持不变\n",
    "  seed: 1111\n",
    "  task_name: '/kaggle/working/doppler'\n",
    "  ldm_batch_size: 4\n",
    "  autoencoder_batch_size: 4\n",
    "  disc_start: 500\n",
    "  disc_weight: 0.8\n",
    "  codebook_weight: 2.0\n",
    "  commitment_beta: 0.5\n",
    "  perceptual_weight: 1.0\n",
    "  kl_weight: 0.0\n",
    "  ldm_epochs: 120\n",
    "  autoencoder_epochs: 40\n",
    "  num_samples: 8\n",
    "  num_grid_rows: 2\n",
    "  ldm_lr: 0.00001\n",
    "  autoencoder_lr: 0.0001\n",
    "  autoencoder_acc_steps: 8\n",
    "  autoencoder_img_save_steps: 8\n",
    "  save_latents: True\n",
    "  vae_latent_dir_name: 'vae_latents'\n",
    "  vqvae_latent_dir_name: 'vqvae_latents'\n",
    "  ldm_ckpt_name: 'ddpm_ckpt.pth'\n",
    "  vqvae_autoencoder_ckpt_name: 'vqvae_autoencoder_ckpt.pth'\n",
    "  vae_autoencoder_ckpt_name: 'vae_autoencoder_ckpt.pth'\n",
    "  vqvae_discriminator_ckpt_name: 'vqvae_discriminator_ckpt.pth'\n",
    "  vae_discriminator_ckpt_name: 'vae_discriminator_ckpt.pth'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 注册数据集类 - 修改train_vqvae.py\n",
    "with open('tools/train_vqvae.py', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# 替换数据集字典\n",
    "content = content.replace(\n",
    "    \"'celebhq': CelebDataset,\", \n",
    "    \"'celebhq': CelebDataset,\\n        'doppler': DopplerDataset,\"\n",
    ")\n",
    "\n",
    "# 添加导入语句\n",
    "content = content.replace(\n",
    "    \"from dataset.mnist_dataset import MnistDataset\",\n",
    "    \"from dataset.mnist_dataset import MnistDataset\\nfrom dataset.doppler_dataset import DopplerDataset\"\n",
    ")\n",
    "\n",
    "with open('tools/train_vqvae.py', 'w') as file:\n",
    "    file.write(content)\n",
    "\n",
    "# 对其他文件执行相同操作\n",
    "for file_path in ['tools/train_ddpm_vqvae.py', 'tools/infer_vqvae.py']:\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    content = content.replace(\n",
    "        \"'celebhq': CelebDataset,\", \n",
    "        \"'celebhq': CelebDataset,\\n        'doppler': DopplerDataset,\"\n",
    "    )\n",
    "    \n",
    "    content = content.replace(\n",
    "        \"from dataset.mnist_dataset import MnistDataset\",\n",
    "        \"from dataset.mnist_dataset import MnistDataset\\nfrom dataset.doppler_dataset import DopplerDataset\"\n",
    "    )\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "print(\"已修改所有训练脚本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 准备工作目录\n",
    "!mkdir -p /kaggle/working/doppler\n",
    "!mkdir -p /kaggle/working/metadata\n",
    "#1. 训练VQ-VAE自编码器\n",
    "!python -m tools.train_vqvae --config config/doppler.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/doppler/vqvae_latents/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. 生成潜在表示\n",
    "!python -m tools.infer_vqvae --config config/doppler.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3. 训练LDM\n",
    "!python -m tools.train_ddpm_vqvae --config config/doppler.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 4. 生成样本\n",
    "!python -m tools.sample_ddpm_vqvae --config config/doppler.yaml"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7585695,
     "sourceId": 12053322,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
